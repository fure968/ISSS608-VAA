---
title: "In Class Exercise 5"
subtitle: " "
author: "Guan Jhen Lin"
date: "May 11 2024"
date-modified: "last-modified"
execute: 
  eval: true
  echo: true
  warning: false
  freeze: true
---

```{r}
pacman::p_load(tidyverse, readtext,
               quanteda, tidytext)
```

```{r}
data_folder <- "data/articles"
```

```{r}
#text_data <- readtext(paste0("data/articles","/*")), class mate found another
#way of writing refer below

text_data <- readtext("data/articles/*")
```

```{r}
corpus_text <- corpus(text_data)
summary(corpus_text, 5)
```

```{r}
usenet_words <- text_data %>% 
  unnest_tokens(word,text) %>%
  filter (str_detect(word,"[a-z']$"),
          !word %in% stop_words$word)

```

```{r}
usenet_words %>%
  count(word, sort = TRUE)
```

You can use stringr package to slice your data, [tidyr](https://tidyr.tidyverse.org/) which is mainly for transforming numerical data, you can use separate wider delim.

```{r}
text_data_splitted <- text_data %>%
  separate_wider_delim("doc_id",
                       delim = "__0__",
                       names = c("X","Y"), 
                       too_few = "align_end")
```



